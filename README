install zookeeper
install kafka
install schema registry
install avro
dotnet add package Confluent.SchemaRegistry.Serdes.Avro


Open a terminal and navigate to the directory where the file is located.

Note: On a OSX bitami kafka

Go through docker-compose.yml and change <HOST_IP> with your local host ip
Do the same with all the services and Java files (change <HOST_IP> with your local host ip

Run

docker-compose up -d

Check if Kafka and Zookeeper are running:

docker-compose ps

Check existing topics

docker exec -it kafka1 /opt/bitnami/kafka/bin/kafka-topics.sh --describe \
  --topic weather-topic \
  --bootstrap-server kafka1:9092

If none, create manually

docker exec -it kafka1 /opt/bitnami/kafka/bin/kafka-topics.sh --create \
  --topic weather-topic \
  --partitions 3 \
  --replication-factor 3 \
  --bootstrap-server kafka1:9092


 docker exec -it kafka1 /opt/bitnami/kafka/bin/kafka-topics.sh --create \
   --topic processed-data-topic \
   --partitions 3 \
   --replication-factor 3 \
   --bootstrap-server kafka1:9092

 docker exec -it kafka1 /opt/bitnami/kafka/bin/kafka-topics.sh --create \
   --topic aggregated-weather-topic \
   --partitions 3 \
   --replication-factor 3 \
   --bootstrap-server kafka1:9092

 docker exec -it kafka1 /opt/bitnami/kafka/bin/kafka-topics.sh --create \
   --topic high-temperature-alerts-topic \
   --partitions 3 \
   --replication-factor 3 \
   --bootstrap-server kafka1:9092


register AVRO schemas

curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
    --data @WeatherPayload.json \
    http://localhost:8081/subjects/weather-topic-value/versions

curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
    --data @ProcessedDataPayload.json \
    http://localhost:8081/subjects/processed-data-topic-value/versions

curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
    --data @AverageTemperaturePayload.json \
    http://localhost:8081/subjects/average-temperature-topic-value/versions

curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
    --data @AggregatedWeatherPayload.json \
    http://localhost:8081/subjects/average-temperature-topic-value/versions



docker-compose up -d

start WeatherStream (java)
start WeatherConsumer (java)
start WeatherAPI (java)

open index html

query locations

check kafka topics

docker exec kafka1 kafka-console-consumer.sh \
  --topic weather-topic \
  --bootstrap-server kafka1:19092 \
  --from-beginning

check mongo

connect to db
weather-app % docker exec -it mongo mongosh weather

check collections
weather> db.getCollectionNames();

check specific collection
db.getCollection('COLLECTION_NAME').find().pretty()

check request
curl -X GET "http://localhost:8080/weather/suggestion?location=Berlin"


Walkthrough:
Input:
User enters New York in the location field and clicks Submit.

Steps:

Frontend sends a request to http://localhost:8080/weather/request?location=New%20York.

Backend fetches weather data for New York from WeatherStack API.

Backend sends the weather data to Kafka (weather-topic).

Kafka Streams aggregates the data and writes it to aggregated-weather-topic.

Kafka Consumer reads the aggregated data and stores it in MongoDB.

Frontend polls http://localhost:8080/weather/suggestion?location=New%20York until data is available.

Frontend displays the aggregated data (e.g., average temperature, number of records).